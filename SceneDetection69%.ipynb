{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhZ35JrGmuhO",
        "outputId": "5a0dfcde-1f66-4fd8-beac-49a80e3c735b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Collecting efficientnet\n",
            "  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.6.3)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet) (0.19.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.6)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (8.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.4.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
            "Installing collected packages: keras-applications, efficientnet\n",
            "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow efficientnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_z94wSKJt9uX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import tarfile\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AyMyUuY__Lwt"
      },
      "outputs": [],
      "source": [
        "# !rm -r Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "d3NnOCyB_Lpk"
      },
      "outputs": [],
      "source": [
        "# !rm -r test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RwjzB1V4_LNI"
      },
      "outputs": [],
      "source": [
        "# !rm -r train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZb_RSNruISR",
        "outputId": "411f48e3-1dee-4e9f-bd7c-f5ffa05e3334"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-07-05 05:53:11--  http://groups.csail.mit.edu/vision/LabelMe/NewImages/indoorCVPR_09.tar\n",
            "Resolving groups.csail.mit.edu (groups.csail.mit.edu)... 128.30.2.44\n",
            "Connecting to groups.csail.mit.edu (groups.csail.mit.edu)|128.30.2.44|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2592010240 (2.4G) [application/x-tar]\n",
            "Saving to: ‘indoorCVPR_09.tar’\n",
            "\n",
            "indoorCVPR_09.tar   100%[===================>]   2.41G  70.9MB/s    in 35s     \n",
            "\n",
            "2023-07-05 05:53:46 (70.2 MB/s) - ‘indoorCVPR_09.tar’ saved [2592010240/2592010240]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://groups.csail.mit.edu/vision/LabelMe/NewImages/indoorCVPR_09.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IX4WYGEjuI5H"
      },
      "outputs": [],
      "source": [
        "with tarfile.open('/content/indoorCVPR_09.tar', 'r') as tar:\n",
        "    tar.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CZzTtQeDuKsX"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/content/Images'\n",
        "\n",
        "images_folder = os.listdir('/content/Images')\n",
        "\n",
        "dest_path = '/content'\n",
        "\n",
        "train_ratio = 0.8\n",
        "\n",
        "for folder in images_folder:\n",
        "  # ['Gym2_000.jpg', 'gimnasio_36_08_flickr.jpg', ... ]\n",
        "  folder_images_list = os.listdir(f'{dataset_path}/{folder}')\n",
        "  train_images, test_images = train_test_split(folder_images_list, test_size=(1 - train_ratio), random_state=42)\n",
        "\n",
        "  for image in train_images:\n",
        "    src = os.path.join(dataset_path, folder, image)\n",
        "    dest = os.path.join(dest_path, \"train\", folder, image)\n",
        "    # print(src,dest)\n",
        "\n",
        "    try:\n",
        "        shutil.copy(src, dest)\n",
        "    except IOError as io_err:\n",
        "        os.makedirs(os.path.dirname(dest))\n",
        "        shutil.copy(src, dest)\n",
        "\n",
        "  for image in test_images:\n",
        "    src = os.path.join(dataset_path, folder, image)\n",
        "    dest = os.path.join(dest_path, \"test\", folder, image)\n",
        "    # print(src,dest)\n",
        "\n",
        "    try:\n",
        "        shutil.copy(src, dest)\n",
        "    except IOError as io_err:\n",
        "        os.makedirs(os.path.dirname(dest))\n",
        "        shutil.copy(src, dest)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zk7K8k9PLzqK"
      },
      "outputs": [],
      "source": [
        "# !pip install -U efficientnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2uFsgcHpuMme"
      },
      "outputs": [],
      "source": [
        "import efficientnet.keras as efn\n",
        "\n",
        "\n",
        "# Load and preprocess your dataset\n",
        "# Assuming your dataset is structured in separate folders for each class,\n",
        "# where each folder contains images belonging to that class.\n",
        "train_dir = '/content/train'\n",
        "validation_dir = '/content/test'\n",
        "image_size = (224, 224)  # Adjust the size according to your requirements\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JM3xL4tHmoKP"
      },
      "outputs": [],
      "source": [
        "!mv \"/content/test/classroom/Imagen_008.jpg\" \"/content\"\n",
        "!mv \"/content/test/gym/gimnasio_74_01_flickr.jpg\" \"/content\"\n",
        "!mv \"/content/test/lobby/lobby21.jpg\" \"/content\"\n",
        "!mv \"/content/test/library/library_bookshelves_large.jpg\" \"/content\"\n",
        "!mv \"/content/test/trainstation/gare_58_16_flickr.jpg\" \"/content\"\n",
        "!mv \"/content/test/mall/West_End_Mall_3_DSC01801_m.jpg\" \"/content\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmJkGgf3w_mb",
        "outputId": "983b9a99-47a7-4f22-e68c-d8c63a5385bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 12467 images belonging to 67 classes.\n",
            "Found 3147 images belonging to 67 classes.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256\n",
        "\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                  #  rotation_range = 40,\n",
        "                                  #  width_shift_range = 0.2,\n",
        "                                  #  height_shift_range = 0.2,\n",
        "                                  #  shear_range = 0.2,\n",
        "                                  #  zoom_range = 0.2,\n",
        "                                   horizontal_flip = True,\n",
        "                                   )\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, batch_size = batch_size, class_mode = 'categorical', target_size = (224, 224),)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory( validation_dir, batch_size = batch_size, class_mode = 'categorical', target_size = (224, 224),)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htyRIVInHKNt",
        "outputId": "82569592-2733-4444-b33f-47e9788540c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
            "16804768/16804768 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model = efn.EfficientNetB0(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')\n",
        "\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IKYFPfAIHKGN"
      },
      "outputs": [],
      "source": [
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "x = Dense(512, activation=\"relu\")(x) # This is new edit of sequential\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# Add a final sigmoid layer with 1 node for classification output\n",
        "predictions = Dense(67, activation=\"softmax\")(x)\n",
        "model_final = tf.keras.models.Model(base_model.input, predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YNQgnygwHN79"
      },
      "outputs": [],
      "source": [
        "model_final.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKX5mg4nHJ6N",
        "outputId": "deca00f1-6b03-4005-a730-130c76ebd44f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "48/48 [==============================] - 171s 3s/step - loss: 3.2536 - accuracy: 0.3200 - val_loss: 1.7734 - val_accuracy: 0.5583\n",
            "Epoch 2/10\n",
            "48/48 [==============================] - 148s 3s/step - loss: 1.7561 - accuracy: 0.5515 - val_loss: 1.3616 - val_accuracy: 0.6244\n",
            "Epoch 3/10\n",
            "48/48 [==============================] - 148s 3s/step - loss: 1.2830 - accuracy: 0.6522 - val_loss: 1.2626 - val_accuracy: 0.6575\n",
            "Epoch 4/10\n",
            "48/48 [==============================] - 148s 3s/step - loss: 0.9855 - accuracy: 0.7263 - val_loss: 1.2230 - val_accuracy: 0.6644\n",
            "Epoch 5/10\n",
            "48/48 [==============================] - 157s 3s/step - loss: 0.7818 - accuracy: 0.7791 - val_loss: 1.2278 - val_accuracy: 0.6768\n",
            "Epoch 6/10\n",
            "48/48 [==============================] - 148s 3s/step - loss: 0.5936 - accuracy: 0.8282 - val_loss: 1.2586 - val_accuracy: 0.6918\n",
            "Epoch 7/10\n",
            "48/48 [==============================] - 158s 3s/step - loss: 0.4901 - accuracy: 0.8581 - val_loss: 1.2750 - val_accuracy: 0.6864\n",
            "Epoch 8/10\n",
            "48/48 [==============================] - 148s 3s/step - loss: 0.4102 - accuracy: 0.8819 - val_loss: 1.3666 - val_accuracy: 0.6838\n",
            "Epoch 9/10\n",
            "48/48 [==============================] - 149s 3s/step - loss: 0.3173 - accuracy: 0.9057 - val_loss: 1.4124 - val_accuracy: 0.6924\n",
            "Epoch 10/10\n",
            "48/48 [==============================] - 147s 3s/step - loss: 0.2935 - accuracy: 0.9133 - val_loss: 1.3923 - val_accuracy: 0.6908\n"
          ]
        }
      ],
      "source": [
        "eff_history = model_final.fit(train_generator, validation_data = validation_generator, steps_per_epoch = train_generator.samples//batch_size, epochs = 10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WN6LMGLTq2p2"
      },
      "outputs": [],
      "source": [
        "model_final.save('/content/drive/MyDrive/69prcnt_accuracy_efficientnet')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "https://drive.google.com/drive/folders/1FMdyCA4O4VA0NI7JzGEHztKm3cCGloUn?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "S__DP1BouSks"
      },
      "outputs": [],
      "source": [
        "!rm -r /content/drive/MyDrive/69prcnt_accuracy_efficientnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "p6xcWG4xuO2-"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0AaQ2plJbjOh"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "X0ecS34wbmRg"
      },
      "outputs": [],
      "source": [
        "# !mv \"/content/test/classroom/Imagen_008.jpg\" \"/content\"\n",
        "# !mv \"/content/test/gym/gimnasio_74_01_flickr.jpg\" \"/content\"\n",
        "# !mv \"/content/test/lobby/lobby21.jpg\" \"/content\"\n",
        "# !mv \"/content/test/library/library_bookshelves_large.jpg\" \"/content\"\n",
        "# !mv \"/content/test/trainstation/gare_58_16_flickr.jpg\" \"/content\"\n",
        "# !mv \"/content/test/mall/West_End_Mall_3_DSC01801_m.jpg\" \"/content\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_lIppZgGhR49"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
        "\n",
        "# # Load the EfficientNetB0 model with pre-trained weights\n",
        "# model = EfficientNetB0(weights='imagenet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlIxvDouVbqg",
        "outputId": "aecb0384-e5ce-4bb6-8f87-c31d8acd0401"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "[44]\n",
            "dentaloffice\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "\n",
        "image_path = \"/content/West_End_Mall_3_DSC01801_m.jpg\"\n",
        "\n",
        "img = load_img(image_path, target_size = (224, 224),)\n",
        "\n",
        "img_array = img_to_array(img)\n",
        "# Add batch dimension\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "img_generator = datagen.flow(img_array, batch_size=20, )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Load and preprocess the image\n",
        "# image = tf.keras.preprocessing.image.load_img('/content/Images/office/office20.jpg', target_size=(224, 224))\n",
        "# image_array = tf.keras.preprocessing.image.img_to_array(image)\n",
        "# preprocessed_image = ImageDataGenerator(rescale = 1.0/255.)\n",
        "\n",
        "\n",
        "# # Reshape the preprocessed image if needed (e.g., for single prediction)\n",
        "# input_image = tf.expand_dims(image_array, axis=0)\n",
        "\n",
        "\n",
        "# Perform the prediction\n",
        "predictions = model_final.predict(img_generator)\n",
        "\n",
        "\n",
        "\n",
        "predicted_class = np.argmax(predictions, axis=1)\n",
        "print(predicted_class)\n",
        "\n",
        "\n",
        "\n",
        "# Map class index to class label using a dictionary\n",
        "predicted_label = images_folder[predicted_class[0]]\n",
        "print(predicted_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SCwsm1WGX3h0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
